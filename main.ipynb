{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8Vm3QEfGELS"
   },
   "source": [
    "### Imports and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "tCni9wAGphb0"
   },
   "outputs": [],
   "source": [
    "# packages for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "# packages for data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# packages for data modeling\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "C9ODhaOppqlw"
   },
   "outputs": [],
   "source": [
    "# load dataset into dataframe\n",
    "data = pd.read_csv(\"tiktok_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYtBhb2zR54G"
   },
   "source": [
    "### Examine data, summary info, and descriptive stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2rfk95MLp4a_"
   },
   "outputs": [],
   "source": [
    "# see data\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kYwW-G1WqX3R"
   },
   "outputs": [],
   "source": [
    "# see data shape\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbpDgrXfEoVj"
   },
   "outputs": [],
   "source": [
    "# get data types of variables\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zyyKCGzCp7SS"
   },
   "outputs": [],
   "source": [
    "# get basic information about variables\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HbpuAS2UqY01"
   },
   "outputs": [],
   "source": [
    "# get basic descriptive stats\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BrunHcfa7xnT"
   },
   "outputs": [],
   "source": [
    "# check for NA\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "SHSj1Hma914I"
   },
   "outputs": [],
   "source": [
    "# fix all NA\n",
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYUF3xap9_Fa"
   },
   "outputs": [],
   "source": [
    "# visualize\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IKaGnWIsiHpH"
   },
   "outputs": [],
   "source": [
    "# check for duplicate entries\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQauKR11fyxb"
   },
   "outputs": [],
   "source": [
    "# check class balance\n",
    "data['claim_status'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8i0spBspquCr"
   },
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Yr9hhhVHeYY"
   },
   "outputs": [],
   "source": [
    "# createing \"transcription_len\"\n",
    "data['transcription_len'] = data['video_transcription_text'].str.len()\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vzg0J8UEJ1wx"
   },
   "outputs": [],
   "source": [
    "# seeing if there's a difference between 'claim' and 'opinino' length\n",
    "data[['transcription_len','claim_status']].groupby('claim_status').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MSq136S3TIYe"
   },
   "outputs": [],
   "source": [
    "# visualize distribution of `transcription_len` for claims and opinions\n",
    "sns.histplot(data=data,\n",
    "             stat='count',\n",
    "             multiple='dodge',\n",
    "             x='transcription_len',\n",
    "             hue='claim_status')\n",
    "plt.xlabel(\"Transcription Length (# char)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Transcription Length for Claims and Opinions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing other categorical variables\n",
    "X = data.copy()\n",
    "X = X.drop(['#','video_id'],axis=1)\n",
    "X['claim_status'] = X['claim_status'].replace({'opinion':0,'claim':1})\n",
    "X = pd.get_dummies(X,\n",
    "                   columns=['verified_status','author_ban_status'],\n",
    "                   drop_first=True)\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6frX3ATWZVgL"
   },
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target variable\n",
    "y = X['claim_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop useless columns\n",
    "X = X.drop(['claim_status','video_transcription_text'],axis=1)\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Create train/validate/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "D5OpxNZYOISV"
   },
   "outputs": [],
   "source": [
    "# split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "A9O-DjLxOJvT"
   },
   "outputs": [],
   "source": [
    "# split train data into training and validation sets\n",
    "X_train, X_value, y_train, y_value = train_test_split(X_train,y_train,test_size=0.25,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TefBRXUu8zWR"
   },
   "outputs": [],
   "source": [
    "# see shapes for all train, validate, test set\n",
    "X_train.shape, X_test.shape, X_value.shape, y_train.shape, y_test.shape, y_value.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_es-Jh1atUz"
   },
   "source": [
    "### Build models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "sNcke2SNvZrN"
   },
   "outputs": [],
   "source": [
    "# building random forest model\n",
    "randf = RandomForestClassifier(random_state=7)\n",
    "hyperparam = {'max_depth':[5,7,None],\n",
    "              'n_estimators':[75,100,200],\n",
    "              'max_features':[0.3,0.6],\n",
    "              'max_samples':[0.7],\n",
    "              'min_samples_leaf':[1,2],\n",
    "              'min_samples_split':[2,3]}\n",
    "scores = {'accuracy','precision','recall','f1'}\n",
    "grid_obj = GridSearchCV(randf,hyperparam,scoring=scores,cv=5,refit='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit random forest model\n",
    "grid_obj.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZG3B_POzPh1s"
   },
   "outputs": [],
   "source": [
    "# seeing recall score\n",
    "grid_obj.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aupWHyY0PlBz"
   },
   "outputs": [],
   "source": [
    "# handling results from random forest classifier\n",
    "grid_results = pd.DataFrame(grid_obj.cv_results_)\n",
    "best_precision_row = grid_results[grid_results['mean_test_precision'] == grid_results['mean_test_precision'].max()]\n",
    "print(best_precision_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qzIDhk-Pq62"
   },
   "outputs": [],
   "source": [
    "# finding best hyperparameters\n",
    "grid_obj.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "A8vLZ_x_QPpF"
   },
   "outputs": [],
   "source": [
    "# building XGboost model\n",
    "boost = XGBClassifier(objective='binary:logistic',random_state=7)\n",
    "boost_param = {'max_depth':[4,8,12],\n",
    "               'min_child_weight':[3,5],\n",
    "               'learning_rate':[0.01,0.1],\n",
    "               'n_estimators':[300,500]}\n",
    "boost_scores = {'accuracy','precision','recall','f1'}\n",
    "boost_obj = GridSearchCV(boost,boost_param,scoring=boost_scores,cv=5,refit='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit boost model\n",
    "boost_obj.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HKoNNFeMQViD"
   },
   "outputs": [],
   "source": [
    "# boost result handling\n",
    "boost_results = pd.DataFrame(boost_obj.cv_results_)\n",
    "boost_bpr = boost_results[boost_results['mean_test_precision'] == boost_results['mean_test_precision'].max()]\n",
    "print(boost_bpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyepBhCTa1Yx"
   },
   "source": [
    "### Evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mdTCEa_cRH8f"
   },
   "outputs": [],
   "source": [
    "# get predictions for random forest\n",
    "\n",
    "y_pred = grid_obj.best_estimator_.predict(X_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t8ppFvJXRL13"
   },
   "outputs": [],
   "source": [
    "# display\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7-mCyVmLRSuz"
   },
   "outputs": [],
   "source": [
    "# display actual labels from testing set\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_YJeJuzvRYPf"
   },
   "outputs": [],
   "source": [
    "# create a confusion matrix to visualize the results of the classification model\n",
    "cf_mat = confusion_matrix(y_value,y_pred)\n",
    "cf_mat_display = ConfusionMatrixDisplay(confusion_matrix=cf_mat,display_labels=None)\n",
    "cf_mat_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kB8e7wfhRrAl"
   },
   "outputs": [],
   "source": [
    "# create a classification report\n",
    "tgt_lab = ['opinion','claim']\n",
    "print(classification_report(y_value,y_pred,target_names=tgt_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fvNxCHqhR9RM"
   },
   "outputs": [],
   "source": [
    "# getting best estimators for boost model\n",
    "y_pred = boost_obj.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O9qpraX-SAjy"
   },
   "outputs": [],
   "source": [
    "# compute values for confusion matrix\n",
    "boost_cf = confusion_matrix(y_test,y_pred)\n",
    "boost_disp = ConfusionMatrixDisplay(confusion_matrix=boost_cf,display_labels=None)\n",
    "boost_disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JcVuGMztSHx4"
   },
   "outputs": [],
   "source": [
    "# create a classification report\n",
    "tgt_lab = ['opinion','claim']\n",
    "print(classification_report(y_value,y_pred,target_names=tgt_lab))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
